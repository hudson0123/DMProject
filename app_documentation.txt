<documents>
<document index="1">
<source>directory-structure.txt</source>
<document_content>
.
├── __pycache__
│   ├── config.cpython-311.pyc
│   └── config.cpython-313.pyc
├── app
│   ├── __pycache__
│   │   ├── __init__.cpython-311.pyc
│   │   ├── __init__.cpython-313.pyc
│   │   ├── models.cpython-311.pyc
│   │   ├── models.cpython-313.pyc
│   │   ├── routes.cpython-311.pyc
│   │   └── routes.cpython-313.pyc
│   ├── static
│   │   ├── distributions
│   │   │   ├── Unnamed: 0_dist.png
│   │   │   ├── acousticness_dist.png
│   │   │   ├── danceability_dist.png
│   │   │   ├── duration_ms_dist.png
│   │   │   ├── energy_dist.png
│   │   │   ├── instrumentalness_dist.png
│   │   │   ├── key_dist.png
│   │   │   ├── liveness_dist.png
│   │   │   ├── loudness_dist.png
│   │   │   ├── mode_dist.png
│   │   │   ├── speechiness_dist.png
│   │   │   ├── tempo_dist.png
│   │   │   ├── time_signature_dist.png
│   │   │   └── valence_dist.png
│   │   ├── correlations.png
│   │   ├── feature_distributions.png
│   │   ├── genre_distribution.png
│   │   └── styles.css
│   ├── templates
│   │   ├── results.html
│   │   └── settings.html
│   ├── utils
│   │   ├── __pycache__
│   │   │   ├── __init__.cpython-311.pyc
│   │   │   ├── __init__.cpython-313.pyc
│   │   │   ├── analysis.cpython-311.pyc
│   │   │   ├── analysis.cpython-313.pyc
│   │   │   ├── data_loader.cpython-311.pyc
│   │   │   ├── data_loader.cpython-313.pyc
│   │   │   ├── model_utils.cpython-311.pyc
│   │   │   ├── model_utils.cpython-313.pyc
│   │   │   ├── visualization.cpython-311.pyc
│   │   │   └── visualization.cpython-313.pyc
│   │   ├── __init__.py
│   │   ├── analysis.py
│   │   ├── data_loader.py
│   │   ├── model_utils.py
│   │   └── visualization.py
│   ├── __init__.py
│   ├── models.py
│   └── routes.py
├── data
│   └── genres_v2.csv
├── .gitignore
├── Dockerfile
├── README.txt
├── app_documentation.txt
├── config.py
├── document-app.sh
├── main.py
└── requirements.txt

10 directories, 55 files
</document_content>
</document>
<document index="2">
<source>./config.py</source>
<document_content>
class Config:
    SECRET_KEY = "your_secret_key"
</document_content>
</document>
<document index="3">
<source>./app/models.py</source>
<document_content>
import numpy as np
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn import tree

# Global configuration
enable_hyperparam_tuning = False  # This will be updated by the routes

# Define models with consistent random states
models = {
    "Multinomial Naive Bayes": MultinomialNB(),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(random_state=42, max_iter=1000),
    "Decision Tree Classifier": tree.DecisionTreeClassifier(random_state=42)
}

# Define hyperparameter grids
param_grids = {
    "Multinomial Naive Bayes": {
        'alpha': [0.1, 0.5, 1.0, 2.0],
        'fit_prior': [True, False]
    },
    "Random Forest": {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 20, 30, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2']
    },
    "Logistic Regression": {
        'C': [0.001, 0.01, 0.1, 1, 10, 100],
        'penalty': ['l1', 'l2'],
        'solver': ['liblinear', 'saga']
    },
    "Decision Tree Classifier": {
        'criterion': ['gini', 'entropy'],
        'max_depth': [5, 10, 20, 30, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2', None]
    }
}</document_content>
</document>
<document index="4">
<source>./app/__init__.py</source>
<document_content>
# app/__init__.py
from flask import Flask
from config import Config

def create_app(config_class=Config):
    """Create and configure the Flask application"""
    app = Flask(__name__)
    app.config.from_object(config_class)
    
    # Initialize extensions here if any
    
    # Register blueprints
    from .routes import home_bp
    app.register_blueprint(home_bp)
    
    return app

# Avoid circular imports by moving these to the end
from .utils.data_loader import load_and_preprocess_data
from .utils.model_utils import train_and_evaluate_models
from .utils.analysis import analyze_dataset, check_data_quality
from .utils.visualization import save_visualizations

__all__ = [
    'create_app',
    'load_and_preprocess_data',
    'train_and_evaluate_models',
    'analyze_dataset',
    'check_data_quality',
    'save_visualizations'
]</document_content>
</document>
<document index="5">
<source>./app/utils/model_utils.py</source>
<document_content>
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, cohen_kappa_score, hamming_loss,
    confusion_matrix, roc_curve, auc
)
import numpy as np
from sklearn.base import clone

def train_and_evaluate_models(X_train, X_test, y_train, y_test):
    """
    Trains and evaluates multiple models.
    """
    try:
        from ..models import models, param_grids, enable_hyperparam_tuning
        results = {}
        
        print(f"\nHyperparameter tuning status: {'Enabled' if enable_hyperparam_tuning else 'Disabled'}")
        
        for model_name, base_model in models.items():
            try:
                print(f"\nTraining {model_name}...")
                
                # Clone the base model to avoid modifying the original
                model = clone(base_model)
                
                if enable_hyperparam_tuning:
                    print(f"Starting hyperparameter search for {model_name}...")
                    print(f"Parameter grid: {param_grids[model_name]}")
                    
                    # Create and fit RandomizedSearchCV
                    random_search = RandomizedSearchCV(
                        estimator=model,
                        param_distributions=param_grids[model_name],
                        n_iter=20,
                        cv=5,
                        verbose=2,
                        random_state=42,
                        n_jobs=-1,
                        scoring='accuracy'
                    )
                    
                    print("Fitting RandomizedSearchCV...")
                    random_search.fit(X_train, y_train)
                    
                    # Get best model and parameters
                    model = random_search.best_estimator_
                    print(f"Best parameters found for {model_name}:")
                    print(random_search.best_params_)
                    print(f"Best cross-validation score: {random_search.best_score_:.3f}")
                    
                else:
                    print(f"Training {model_name} with default parameters...")
                    model.fit(X_train, y_train)
                
                # Make predictions
                y_pred = model.predict(X_test)
                
                # Calculate metrics
                metrics = calculate_metrics(model, X_test, y_test, y_pred)
                
                # Add hyperparameter tuning results if applicable
                if enable_hyperparam_tuning:
                    metrics['best_params'] = random_search.best_params_
                    metrics['cv_score'] = random_search.best_score_
                    
                results[model_name] = metrics
                
            except Exception as model_error:
                print(f"Error training {model_name}: {str(model_error)}")
                results[model_name] = create_error_metrics()
        
        return results
        
    except Exception as e:
        print(f"Error in train_and_evaluate_models: {str(e)}")
        return {"Error": create_error_metrics()}

def calculate_metrics(model, X_test, y_test, y_pred):
    """Calculates all metrics for a model."""
    try:
        metrics = {
            "model": model,
            "best_params": model.get_params(),
            "accuracy": accuracy_score(y_test, y_pred),
            "precision_weighted": precision_score(y_test, y_pred, average='weighted', zero_division=0),
            "recall_weighted": recall_score(y_test, y_pred, average='weighted', zero_division=0),
            "f1_weighted": f1_score(y_test, y_pred, average='weighted', zero_division=0),
            "cohen_kappa": cohen_kappa_score(y_test, y_pred),
            "hamming_loss": hamming_loss(y_test, y_pred),
            "classification_report": classification_report(y_test, y_pred, output_dict=True, zero_division=0),
            "confusion_matrix": confusion_matrix(y_test, y_pred)
        }
        
        # Add ROC curve data if model supports predict_proba
        if hasattr(model, 'predict_proba'):
            metrics["roc_data"] = calculate_roc_curves(model, X_test, y_test)
            
        return metrics
        
    except Exception as e:
        print(f"Error in calculate_metrics: {str(e)}")
        return create_error_metrics()

def create_error_metrics():
    """Creates a dictionary of error metrics when model training fails"""
    return {
        "model": None,
        "best_params": "Error during training",
        "accuracy": 0.0,
        "precision_weighted": 0.0,
        "recall_weighted": 0.0,
        "f1_weighted": 0.0,
        "cohen_kappa": 0.0,
        "hamming_loss": 1.0,
        "classification_report": {
            "error": {
                "precision": 0.0,
                "recall": 0.0,
                "f1-score": 0.0,
                "support": 0
            }
        },
        "confusion_matrix": np.zeros((1, 1))
    }

def calculate_roc_curves(model, X_test, y_test):
    """Calculates ROC curves for multi-class classification."""
    try:
        y_prob = model.predict_proba(X_test)
        n_classes = y_prob.shape[1]
        roc_data = {}
        
        for i in range(n_classes):
            fpr, tpr, _ = roc_curve(y_test == i, y_prob[:, i])
            roc_data[i] = {
                'fpr': fpr.tolist(),
                'tpr': tpr.tolist(),
                'auc': float(auc(fpr, tpr))
            }
        
        return roc_data
        
    except Exception as e:
        print(f"Error in calculate_roc_curves: {str(e)}")
        return {}</document_content>
</document>
<document index="6">
<source>./app/utils/analysis.py</source>
<document_content>
# Configure matplotlib first
import matplotlib
matplotlib.use('Agg')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

def analyze_dataset(df):
    """
    Performs comprehensive analysis of the dataset.
    
    Parameters:
    df (pandas.DataFrame): Input dataset
    
    Returns:
    dict: Dictionary containing analysis results
    """
    try:
        # Basic dataset statistics
        stats = {
            "total_records": len(df),
            "features": len(df.columns),
            "genres": df['genre'].nunique(),
            "genre_distribution": df['genre'].value_counts().to_dict(),
            "missing_values": df.isnull().sum().to_dict(),
            "feature_stats": df.describe().to_dict()
        }
        
        # Check for class imbalance
        genre_counts = df['genre'].value_counts()
        stats["imbalance_ratio"] = genre_counts.max() / genre_counts.min()
        
        # Feature correlations for numerical columns
        numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns
        stats["correlations"] = df[numerical_cols].corr()
        
        # Generate and save visualizations
        from .visualization import save_visualizations
        save_visualizations(df, stats)
        
        return stats
        
    except Exception as e:
        print(f"Error in analyze_dataset: {str(e)}")
        raise

def check_data_quality(df):
    """
    Performs data quality checks.
    
    Parameters:
    df (pandas.DataFrame): Input dataset
    
    Returns:
    dict: Dictionary containing quality check results
    """
    try:
        quality_checks = {
            "duplicates": df.duplicated().sum(),
            "missing_values": df.isnull().sum().to_dict(),
            "feature_ranges": {
                col: {
                    "min": df[col].min(), 
                    "max": df[col].max()
                } 
                for col in df.select_dtypes(include=['float64', 'int64']).columns
            },
            "outliers": {}
        }
        
        # Check for outliers using IQR method
        for col in df.select_dtypes(include=['float64', 'int64']).columns:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            outliers = ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))).sum()
            quality_checks["outliers"][col] = outliers
        
        return quality_checks
        
    except Exception as e:
        print(f"Error in check_data_quality: {str(e)}")
        raise</document_content>
</document>
<document index="7">
<source>./app/utils/data_loader.py</source>
<document_content>
import pandas as pd
import numpy as np
import scipy.sparse
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from imblearn.over_sampling import SMOTE

def load_and_preprocess_data(filename, use_smote=False):
    """
    Loads data from a CSV file, analyzes it, and preprocesses it for model training.
    """
    try:
        # Load data
        data_path = f"data/{filename}"
        df = pd.read_csv(data_path, low_memory=False)
        
        # Drop unwanted columns
        df = df.drop(columns=[col for col in df.columns if 'Unnamed' in col], errors='ignore')
        df = df.drop([
            "type", "id", "uri", "track_href", "analysis_url", "song_name", 
            "title"
        ], axis=1)
        
        # Store original analysis
        from .analysis import analyze_dataset, check_data_quality
        original_analysis = analyze_dataset(df.copy())
        quality_checks = check_data_quality(df.copy())
        original_analysis['quality_checks'] = quality_checks
        
        # Separate features and target
        X = df.drop(['genre'], axis=1)
        y = df['genre']
        
        # Initial train-test split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Create preprocessing pipeline
        numerical_features = X.select_dtypes(include=['float64', 'int64']).columns
        categorical_features = X.select_dtypes(include=['object']).columns
        
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', Pipeline([
                    ('imputer', SimpleImputer(strategy='median')),
                    ('scaler', MinMaxScaler())
                ]), numerical_features),
                ('cat', Pipeline([
                    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
                    ('encoder', OneHotEncoder(handle_unknown='ignore'))
                ]), categorical_features)
            ])
        
        # Fit and transform the training data
        X_train_processed = preprocessor.fit_transform(X_train)
        X_test_processed = preprocessor.transform(X_test)
        
        if use_smote:
            print("\nApplying SMOTE...")
            print("\nClass distribution before SMOTE:")
            print(y_train.value_counts())
            
            # Apply SMOTE
            smote = SMOTE(random_state=42)
            X_train_processed, y_train = smote.fit_resample(X_train_processed, y_train)
            
            # Convert sparse matrix back to dense for analysis if needed
            if scipy.sparse.issparse(X_train_processed):
                X_train_dense = X_train_processed.toarray()
            else:
                X_train_dense = X_train_processed
                
            # Create a DataFrame with the SMOTE-processed data for analysis
            columns = numerical_features.tolist()  # Get original feature names
            smote_df = pd.DataFrame(X_train_dense, columns=columns)
            smote_df['genre'] = y_train
            
            # Perform analysis on SMOTE-processed data
            analysis_results = analyze_dataset(smote_df)
            analysis_results['quality_checks'] = quality_checks  # Keep original quality checks
            
            print("\nClass distribution after SMOTE:")
            print(pd.Series(y_train).value_counts())
        else:
            analysis_results = original_analysis
        
        # Store distribution info
        analysis_results['original_class_distribution'] = y_train.value_counts().to_dict()
        if use_smote:
            analysis_results['smote_class_distribution'] = pd.Series(y_train).value_counts().to_dict()
        analysis_results['smote_applied'] = use_smote
        
        return X_train_processed, X_test_processed, y_train, y_test, analysis_results
        
    except Exception as e:
        print(f"Error in load_and_preprocess_data: {str(e)}")
        raise</document_content>
</document>
<document index="8">
<source>./app/utils/__init__.py</source>
<document_content>
from .data_loader import load_and_preprocess_data
from .model_utils import train_and_evaluate_models
from .analysis import analyze_dataset, check_data_quality
from .visualization import save_visualizations

__all__ = [
    'load_and_preprocess_data',
    'train_and_evaluate_models',
    'analyze_dataset',
    'check_data_quality',
    'save_visualizations'
]</document_content>
</document>
<document index="9">
<source>./app/utils/visualization.py</source>
<document_content>
import matplotlib.pyplot as plt
import seaborn as sns
import os

def save_visualizations(df, stats):
    """
    Generates and saves visualizations.
    
    Parameters:
    df (pandas.DataFrame): Input dataset
    stats (dict): Statistics dictionary from analyze_dataset
    """
    try:
        # Create static directory if it doesn't exist
        if not os.path.exists('app/static'):
            os.makedirs('app/static')
        
        # Set style for all plots
        plt.style.use('seaborn')
        
        # Genre distribution plot
        create_genre_distribution(df)
        
        # Correlation heatmap
        create_correlation_heatmap(df, stats)
        
        # Feature distributions
        create_feature_distributions(df)
        
    except Exception as e:
        print(f"Error in save_visualizations: {str(e)}")
        plt.close('all')  # Make sure to close all figures in case of error
        raise

def create_feature_distributions(df):
    """Creates and saves individual feature distribution plots."""
    try:
        # Define the numeric features we want to plot
        features_to_plot = [
            'danceability', 'energy', 'key', 'loudness', 
            'speechiness', 'acousticness', 'instrumentalness',
            'liveness', 'valence', 'tempo', 'duration_ms'
        ]
        
        # Filter features that actually exist in the dataframe
        features_to_plot = [f for f in features_to_plot if f in df.columns]
        
        # Create directory for individual plots if it doesn't exist
        dist_dir = 'app/static/distributions'
        os.makedirs(dist_dir, exist_ok=True)
        
        # Create individual plots
        for col in features_to_plot:
            plt.figure(figsize=(10, 10))
            
            # Create the distribution plot with improved styling
            sns.histplot(data=df, x=col, kde=True, color='#4A90E2')
            
            # Customize the plot
            plt.title(col.replace('_', ' ').title(), fontsize=16, pad=20)
            plt.xlabel(col.replace('_', ' ').title(), fontsize=14)
            plt.ylabel('Count', fontsize=14)
            plt.xticks(fontsize=12, rotation=45)
            plt.yticks(fontsize=12)
            
            # Add grid and style improvements
            plt.grid(True, alpha=0.3, linestyle='--')
            plt.gca().spines['top'].set_visible(False)
            plt.gca().spines['right'].set_visible(False)
            
            # Improve plot background
            plt.gca().set_facecolor('#f8f9fa')
            plt.gcf().set_facecolor('white')
            
            # Add padding to prevent label cutoff
            plt.tight_layout(pad=2.0)
            
            # Save individual plot with high resolution
            plt.savefig(f'{dist_dir}/{col}_dist.png', 
                       dpi=150,
                       bbox_inches='tight',
                       pad_inches=0.3,
                       facecolor='white')
            plt.close()
            
    except Exception as e:
        print(f"Error in create_feature_distributions: {str(e)}")
        plt.close('all')
        raise

def create_correlation_heatmap(df, stats):
    """Creates and saves the correlation heatmap."""
    try:
        plt.figure(figsize=(15, 12))  # Increased figure size
        
        # Ensure we exclude the Unnamed column and other non-numeric columns
        df_clean = df.select_dtypes(include=['float64', 'int64'])
        df_clean = df_clean.drop(['Unnamed: 0'], axis=1, errors='ignore')
        
        correlation_matrix = df_clean.corr()
        
        # Create heatmap with larger annotations
        sns.heatmap(correlation_matrix, 
                   annot=True, 
                   cmap='coolwarm', 
                   center=0,
                   fmt='.2f',
                   annot_kws={'size': 10})
        
        plt.title('Feature Correlations', pad=20)
        plt.tight_layout()
        plt.savefig('app/static/correlations.png', dpi=300, bbox_inches='tight')
        plt.close()
        
    except Exception as e:
        print(f"Error in create_correlation_heatmap: {str(e)}")
        plt.close('all')
        raise

def create_genre_distribution(df):
    """Creates and saves the genre distribution plot."""
    try:
        plt.figure(figsize=(15, 10))  # Increased figure size
        
        # Create countplot with rotated labels
        sns.countplot(data=df, 
                     y='genre', 
                     order=df['genre'].value_counts().index)
        
        plt.title('Genre Distribution', pad=20)
        plt.xlabel('Count')
        plt.ylabel('Genre')
        
        plt.tight_layout()
        plt.savefig('app/static/genre_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        
    except Exception as e:
        print(f"Error in create_genre_distribution: {str(e)}")
        plt.close('all')
        raise</document_content>
</document>
<document index="10">
<source>./app/static/styles.css</source>
<document_content>
/* Base Styles */
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
    line-height: 1.6;
    color: #333;
    background-color: #f5f5f5;
}

.container {
    max-width: 95%;
    margin: 0 auto;
    padding: 20px;
}

h1 {
    color: #2c3e50;
    margin-bottom: 30px;
    text-align: center;
    font-size: 2.5em;
}

h2 {
    color: #34495e;
    margin: 25px 0 15px;
    font-size: 1.8em;
}

/* Analysis Section */
.analysis-section {
    background: white;
    border-radius: 8px;
    padding: 20px;
    margin-bottom: 30px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

.stats-box {
    background: #f8f9fa;
    padding: 20px;
    border-radius: 6px;
    margin-bottom: 20px;
}

.stats-box h3 {
    color: #2c3e50;
    margin-bottom: 15px;
}

.stats-box ul {
    list-style: none;
}

.stats-box li {
    padding: 8px 0;
    border-bottom: 1px solid #eee;
}

/* Visualizations */
.visualizations {
    display: flex;
    flex-direction: column;
    gap: 30px;
    margin: 20px 0;
}

.visualization-box {
    background: white;
    padding: 20px;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    width: 100%;
}

.visualization-box h3 {
    color: #2c3e50;
    margin-bottom: 15px;
    font-size: 1.2em;
}

.visualization-box img {
    width: 100%;
    max-height: 600px;
    object-fit: contain;
    border-radius: 4px;
}

/* Feature Distributions Grid Container */
.feature-distributions-container {
    display: flex;
    flex-direction: column;
    gap: 20px;
    padding: 20px;
    background: white;
    border-radius: 8px;
    margin-top: 30px;
}

/* Main 3x3 Grid */
.feature-distributions-main {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: 20px;
    width: 100%;
}

/* Bottom Row with 2 plots */
.feature-distributions-bottom {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 20px;
    width: 66.67%; /* Takes up same width as 2/3 of the grid above */
    margin: 0 auto; /* Centers the bottom row */
}

.distribution-graph {
    aspect-ratio: 1;  /* Maintains square shape */
    width: 100%;
}

.distribution-graph img {
    width: 100%;
    height: 100%;
    object-fit: contain;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.05);
}

/* Model Results */
.models-container {
    display: grid;
    grid-template-columns: repeat(2, 1fr); /* Two columns */
    grid-template-rows: repeat(2, auto);  /* Two rows */
    gap: 20px;
    margin-top: 20px;
}

.model-result {
    background: white;
    padding: 20px;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

.model-result h3 {
    color: #2c3e50;
    margin-bottom: 15px;
    font-size: 1.3em;
    padding: 0;
    background: none;
    box-shadow: none;
}

.model-result ul {
    list-style: none;
    margin: 15px 0;
    padding: 0;
}

.model-result li {
    padding: 5px 0;
    margin: 0;
    background: none;
    box-shadow: none;
}

/* Table Container */
.table-container {
    overflow-x: auto;
    margin: 15px 0;
    overflow-y: auto;
    background: white;
    border-radius: 4px;
}

/* Classification Table */
.classification-table {
    width: 100%;
    border-collapse: collapse;
    margin: 0;
    border: none;
}

.classification-table th,
.classification-table td {
    padding: 8px;
    text-align: left;
    border: 1px solid #ddd;
    background: none;
    box-shadow: none;
}

.classification-table th {
    background-color: #f8f9fa;
    font-weight: 600;
    position: sticky;
    top: 0;
    z-index: 1;
}

.classification-table tr:nth-child(even) {
    background-color: #f8f9fa;
}

/* Remove any nested boxes */
.model-result > div,
.model-result > section {
    background: none;
    box-shadow: none;
    padding: 0;
    margin: 0;
    border: none;
}

/* Responsive Design */
@media (max-width: 1200px) {
    .feature-distributions {
        grid-template-columns: repeat(2, 1fr);
    }
}

@media (max-width: 768px) {
    .container {
        padding: 10px;
        max-width: 100%;
    }
    
    .feature-distributions {
        grid-template-columns: 1fr;
    }
    
    .models-container {
        grid-template-columns: 1fr;
    }
}</document_content>
</document>
<document index="11">
<source>./app/templates/results.html</source>
<document_content>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Music Genre Classification Results</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='styles.css') }}">
</head>
<body>
    <div class="container">
        {% if model_results and model_results.get('Error') %}
        <div class="error-message">
            <h2>Error During Analysis</h2>
            <p>An error occurred while processing the models. Please try again or contact support if the issue persists.</p>
        </div>
        {% endif %}
        <h1>Music Genre Classification Results</h1>
        <div class="smote-toggle">
            <h2>SMOTE Settings</h2>
            <div class="toggle-container">
                <span>SMOTE is currently: {{ 'Enabled' if use_smote else 'Disabled' }}</span>
                <form method="get" class="toggle-form">
                    <input type="hidden" name="use_smote" value="{{ 'false' if use_smote else 'true' }}">
                    <button type="submit" class="toggle-button {{ 'active' if use_smote else '' }}">
                        {{ 'Disable SMOTE' if use_smote else 'Enable SMOTE' }}
                    </button>
                </form>
            </div>
            {% if analysis_results.smote_applied %}
            <div class="distribution-comparison">
                <div class="distribution-box">
                    <h3>Original Class Distribution</h3>
                    <ul>
                        {% for genre, count in analysis_results.original_class_distribution.items() %}
                        <li>{{ genre }}: {{ count }}</li>
                        {% endfor %}
                    </ul>
                </div>
                <div class="distribution-box">
                    <h3>SMOTE-Balanced Distribution</h3>
                    <ul>
                        {% for genre, count in analysis_results.smote_class_distribution.items() %}
                        <li>{{ genre }}: {{ count }}</li>
                        {% endfor %}
                    </ul>
                </div>
            </div>
            {% endif %}
        </div>
        <!-- Dataset Analysis Section -->
        {% if analysis_results %}
            <h2>Dataset Analysis</h2>
            <div class="analysis-section">
                <div class="stats-box">
                    <h3>Dataset Statistics</h3>
                    <ul>
                        <li>Total Records: {{ analysis_results.total_records }}</li>
                        <li>Number of Features: {{ analysis_results.features }}</li>
                        <li>Number of Genres: {{ analysis_results.genres }}</li>
                        <li>Class Imbalance Ratio: {{ "%.2f"|format(analysis_results.imbalance_ratio) }}</li>
                    </ul>
                </div>

                <!-- Visualizations -->
                <div class="visualizations">
                    <div class="visualization-box">
                        <h3>Genre Distribution</h3>
                        <img src="{{ url_for('static', filename='genre_distribution.png') }}" alt="Genre Distribution">
                    </div>
                    <div class="visualization-box">
                        <h3>Feature Correlations</h3>
                        <img src="{{ url_for('static', filename='correlations.png') }}" alt="Feature Correlations">
                    </div>
                    <div class="visualization-box">
                        <h3>Feature Distributions</h3>
                        <div class="feature-distributions-container">
                            <div class="feature-distributions-main">
                                {% for feature in ['danceability', 'energy', 'key', 
                                                 'loudness', 'speechiness', 'acousticness', 
                                                 'instrumentalness', 'liveness', 'valence'] %}
                                    <div class="distribution-graph">
                                        <img src="{{ url_for('static', filename='distributions/' + feature + '_dist.png') }}" 
                                             alt="{{ feature }} distribution"
                                             title="{{ feature }} distribution">
                                    </div>
                                {% endfor %}
                            </div>
                            <div class="feature-distributions-bottom">
                                {% for feature in ['tempo', 'duration_ms'] %}
                                    <div class="distribution-graph">
                                        <img src="{{ url_for('static', filename='distributions/' + feature + '_dist.png') }}" 
                                             alt="{{ feature }} distribution"
                                             title="{{ feature }} distribution">
                                    </div>
                                {% endfor %}
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Data Quality -->
                {% if analysis_results.quality_checks %}
                <div class="quality-box">
                    <h3>Data Quality Checks</h3>
                    <ul>
                        <li>Duplicate Records: {{ analysis_results.quality_checks.duplicates }}</li>
                        <li>Missing Values: {{ analysis_results.quality_checks.missing_values | length }}</li>
                    </ul>
                </div>
                {% endif %}
            </div>
        {% endif %}

        <!-- Model Results Section -->
        {% if model_results %}
            <h2>Model Evaluation Metrics</h2>
            <div class="models-container">
                {% for model_name, metrics in model_results.items() %}
                    {% if metrics and metrics.model is not none %}  <!-- Only show if metrics are valid -->
                        <div class="model-result">
                            <h3>{{ model_name }}</h3>
                            {% if use_hyperopt and metrics.get('best_params') and metrics.best_params != "Error during training" %}
                            <div class="hyperparameters">
                                <h4>Best Parameters:</h4>
                                <ul>
                                {% for param, value in metrics.best_params.items() %}
                                    <li><strong>{{ param }}:</strong> {{ value }}</li>
                                {% endfor %}
                                </ul>
                                {% if metrics.get('cv_score') %}
                                <p><strong>Best Cross-Validation Score:</strong> {{ "%.3f"|format(metrics.cv_score) }}</p>
                                {% endif %}
                            </div>
                            {% endif %}
                            <h3>{{ model_name }}</h3>
                            <ul>
                                <li><strong>Accuracy:</strong> {{ "%.3f"|format(metrics.accuracy) }}</li>
                                <li><strong>Precision (Weighted):</strong> {{ "%.3f"|format(metrics.precision_weighted) }}</li>
                                <li><strong>Recall (Weighted):</strong> {{ "%.3f"|format(metrics.recall_weighted) }}</li>
                                <li><strong>F1 Score (Weighted):</strong> {{ "%.3f"|format(metrics.f1_weighted) }}</li>
                                <li><strong>Cohen's Kappa:</strong> {{ "%.3f"|format(metrics.cohen_kappa) }}</li>
                                <li><strong>Hamming Loss:</strong> {{ "%.3f"|format(metrics.hamming_loss) }}</li>
                            </ul>
                            {% if metrics.classification_report %}
                                <h4>Classification Report:</h4>
                                <div class="table-container">
                                    <table class="classification-table">
                                        <thead>
                                            <tr>
                                                <th>Label</th>
                                                <th>Precision</th>
                                                <th>Recall</th>
                                                <th>F1-Score</th>
                                                <th>Support</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            {% for label, scores in metrics.classification_report.items() if label not in ['accuracy', 'macro avg', 'weighted avg', 'error'] %}
                                                <tr>
                                                    <td>{{ label }}</td>
                                                    <td>{{ "%.2f"|format(scores.precision) }}</td>
                                                    <td>{{ "%.2f"|format(scores.recall) }}</td>
                                                    <td>{{ "%.2f"|format(scores['f1-score']) }}</td>
                                                    <td>{{ scores.support }}</td>
                                                </tr>
                                            {% endfor %}
                                        </tbody>
                                    </table>
                                </div>
                            {% endif %}
                        </div>
                    {% endif %}
                {% endfor %}
            </div>
        {% else %}
            <p class="flash-message">No results available. Please check the data and try again.</p>
        {% endif %}
    </div>    
</body>
</html></document_content>
</document>
<document index="12">
<source>./app/templates/settings.html</source>
<document_content>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Music Genre Classification Settings</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
            margin: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
        }

        .container {
            background: white;
            padding: 2rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            max-width: 500px;
            width: 90%;
        }

        h1 {
            color: #2c3e50;
            margin-bottom: 1.5rem;
            text-align: center;
            font-size: 2rem;
        }

        .settings-form {
            display: flex;
            flex-direction: column;
            gap: 1.5rem;
        }

        .setting-option {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 6px;
        }

        .setting-option h2 {
            color: #34495e;
            margin: 0 0 0.5rem 0;
            font-size: 1.2rem;
        }

        .setting-option p {
            margin: 0 0 1rem 0;
            color: #666;
            font-size: 0.9rem;
        }

        .toggle-switch {
            display: flex;
            align-items: center;
            gap: 1rem;
        }

        .submit-button {
            background: #3498db;
            color: white;
            border: none;
            padding: 1rem;
            border-radius: 6px;
            cursor: pointer;
            font-size: 1rem;
            transition: background 0.3s ease;
        }

        .submit-button:hover {
            background: #2980b9;
        }

        .toggle-switch input[type="checkbox"] {
            width: 3rem;
            height: 1.5rem;
            appearance: none;
            background: #ddd;
            border-radius: 1.5rem;
            position: relative;
            cursor: pointer;
            transition: background 0.3s ease;
        }

        .toggle-switch input[type="checkbox"]::before {
            content: '';
            width: 1.3rem;
            height: 1.3rem;
            background: white;
            border-radius: 50%;
            position: absolute;
            top: 0.1rem;
            left: 0.1rem;
            transition: transform 0.3s ease;
        }

        .toggle-switch input[type="checkbox"]:checked {
            background: #2ecc71;
        }

        .toggle-switch input[type="checkbox"]:checked::before {
            transform: translateX(1.5rem);
        }

        .toggle-label {
            font-weight: 500;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Music Genre Classification Settings</h1>
        <form action="/analyze" method="get" class="settings-form">
            <div class="setting-option">
                <h2>SMOTE (Synthetic Minority Over-sampling Technique)</h2>
                <p>Balances the dataset by generating synthetic examples for minority classes. This can improve classification performance for imbalanced datasets.</p>
                <div class="toggle-switch">
                    <input type="checkbox" id="use_smote" name="use_smote" value="true">
                    <span class="toggle-label">Enable SMOTE</span>
                </div>
            </div>

            <div class="setting-option">
                <h2>Hyperparameter Tuning</h2>
                <p>Automatically finds the best parameters for each model. This improves accuracy but significantly increases processing time.</p>
                <div class="toggle-switch">
                    <input type="checkbox" id="use_hyperopt" name="use_hyperopt" value="true">
                    <span class="toggle-label">Enable Hyperparameter Tuning</span>
                </div>
            </div>

            <button type="submit" class="submit-button">Start Analysis</button>
        </form>
    </div>
</body>
</html></document_content>
</document>
<document index="13">
<source>./app/routes.py</source>
<document_content>
from flask import Blueprint, render_template, flash, request, redirect, url_for
from .utils import load_and_preprocess_data, train_and_evaluate_models
import sys

home_bp = Blueprint("home", __name__, template_folder="templates")

@home_bp.route("/", methods=['GET'])
def home():
    """Landing page with settings form"""
    return render_template("settings.html")

@home_bp.route("/analyze", methods=['GET'])
def analyze():
    """Process the analysis with selected settings"""
    try:
        # Get settings from query parameters
        use_smote = request.args.get('use_smote', 'false').lower() == 'true'
        use_hyperopt = request.args.get('use_hyperopt', 'false').lower() == 'true'
        
        # Update hyperparameter tuning setting in models.py
        from .models import enable_hyperparam_tuning
        # Force reload the models module to update the global variable
        import importlib
        from . import models
        importlib.reload(models)
        models.enable_hyperparam_tuning = use_hyperopt
        
        print(f"\nSettings applied:")
        print(f"SMOTE: {use_smote}")
        print(f"Hyperparameter Tuning: {use_hyperopt}")
        
        # Load, analyze, and preprocess data
        X_train, X_test, y_train, y_test, analysis_results = load_and_preprocess_data(
            "genres_v2.csv",
            use_smote=use_smote
        )
        
        # Train models and evaluate performance
        model_results = train_and_evaluate_models(X_train, X_test, y_train, y_test)
        
    except Exception as e:
        print(f"Error: {str(e)}", file=sys.stderr)
        model_results = {}
        analysis_results = {}
        flash(f"An error occurred: {str(e)}", "error")
    
    # Render template with all results
    return render_template(
        "results.html",
        model_results=model_results,
        analysis_results=analysis_results,
        use_smote=use_smote,
        use_hyperopt=use_hyperopt
    )</document_content>
</document>
<document index="14">
<source>./requirements.txt</source>
<document_content>
blinker==1.9.0
click==8.1.7
Flask==3.0.3
itsdangerous==2.2.0
Jinja2==3.1.4
joblib==1.3.2
MarkupSafe==3.0.2
numpy==1.24.3
pandas==2.0.3
python-dateutil==2.9.0.post0
pytz==2024.2
scikit-learn==1.2.2
scipy==1.10.1
six==1.16.0
threadpoolctl==3.2.0
tzdata==2024.2
Werkzeug==3.1.0
seaborn==0.12.2
matplotlib==3.7.2
imbalanced-learn==0.10.1</document_content>
</document>
<document index="15">
<source>./README.txt</source>
<document_content>

# Music Genre Classification API

This application classifies music genres using Spotify API data. It runs four classifiers—Multinomial Naive Bayes, Random Forest, Support Vector Classifier, and Logistic Regression—and evaluates model performance using various metrics. Hyperparameter tuning can be enabled or disabled as needed.

## Getting Started

Follow these steps to set up and run the application locally using Docker.

### Prerequisites
- Docker installed on your machine.

### Installation and Setup

1. Build the Docker Image
   ```
   docker build . -t <ImageName>
   ```
   Replace `<ImageName>` with your preferred name for the Docker image.

2. Run the Docker Container
   ```
   docker run -p 5000:5000 <ImageName>
   ```
   This will start the Flask application on port `5000`.

3. Access the Application
   - Open your browser and go to: http://localhost:5000. Give the application time to load the data and train the model. This will take much longer with hyperparameter tuning set at True and additional models added to the models dictionary.

## Model Details

The application currently supports the following classifiers:
- Multinomial Naive Bayes
- Random Forest (currently configured with hyperparameter tuning enabled by default)
- Support Vector Classifier (SVC)
- Logistic Regression

### Hyperparameter Tuning
- Hyperparameter tuning is currently disabled for Random Forest.
- To enable or disable tuning for specific models, adjust the `enable_hyperparam_tuning` variable in the code.

## Evaluation Techniques

The following evaluation metrics are used to assess model performance:
- Accuracy
- Precision (weighted)
- Recall (weighted)
- F1 Score (weighted)
- Cohen's Kappa
- Hamming Loss
- Classification Report

These metrics are displayed on the application page once the models have been trained and evaluated.

## Authors
- Hudson O'Donnell
- Jackson Davis</document_content>
</document>
<document index="16">
<source>./main.py</source>
<document_content>
from app import create_app

app = create_app()

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
</document_content>
</document>
</documents>
